---
title: Linux IO模式
date: 2021-07-05 11:10:22
permalink: /pages/7156ef/
categories:
  - 系统架构
  - 分布式理论
tags:
  - 网络IO模型
  - 多路复用
  - 异步
---
[[toc]]

在网络编程中，客户端调用服务端发起网络调用的过程是：客户端进程发起调用给服务端 -> 服务端进程收到调用后进行业务处理，然后返回处理结果的消息给调用方；这个过程中存在同步，异步，阻塞，非阻塞相关概念；

<!-- more -->

### 同步，异步，阻塞，非阻塞

**同步和异步：**

1. **同步**就是一个任务的完成需要依赖另外一个任务时，只有等到它依赖的任务完成后，他才能继续进行，这是一种可靠的任务序列。
2. **异步**就是不需要等待依赖的任务完成，只是告诉它该完成什么工作，而我继续干自己的事情，等到它完成后再主动通知我。  （通知可以使用轮询监控变量的变化也可以使用回调机制）

**阻塞和非阻塞：**

阻塞和非阻塞主要是针对调用者**线程** 来说的

1. **阻塞**，就是被调用者没有接收完数据或者没有得到结果之前，当前线程会被挂起（线程进入不可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。此时被调用者不会返回，函数只有在得到结果之后才会返回（别人的调用被我阻塞了）；
2. **非阻塞**，非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回；

**同步的实现方式：同步阻塞和同步非阻塞**

- (a) 如果当前线程在等待函数返回时不处理其他任务，而是处于挂起等待状态，那这种情况就叫做同步阻塞；只专心做一件事情，别的什么都不做，效率最低
- (b) 如果当前线程在等待函数返回时仍在执行其他消息处理，那这种情况就叫做同步非阻塞；虽然线程未被 依赖函数阻塞，使调用方可以做其他事情，但是调用方需要不断观察依赖函数的执行情况；效率很低；

**异步的实现方式：异步阻塞和异步非阻塞**

- (a) 异步阻塞：调用方发起调用后就回到自己的任务等着处理结果,不做其他事情，当被调用方处理完成后会回调通知调用方，告诉他执行结果；此时调用方的执行是异步的，但是在获取结果的时候是被阻塞的。
- (b) 异步非阻塞：调用方发起调用后，可以接着做别的事情；被调用方执行完成后会主动通知你执行结果；调用方不会取询问被调用方的执行结果。



**举例说明：**

> 1. 同步阻塞：小明一直盯着下载进度条，到 100% 的时候就完成。
> 2. 同步非阻塞：小明提交下载任务后就去干别的，每过一段时间就去瞄一眼进度条，看到 100% 就完成。
> 3. 异步阻塞：小明换了个有下载完成通知功能的软件，下载完成就“叮”一声。不过小明仍然一直等待“叮”的声音。（异步体现在：下载完成“叮”一声通知；阻塞体现在：等待下载完成“叮”一声通知过程中，不能做其他任务处理；）
> 4. 异步非阻塞：仍然是那个会“叮”一声的下载软件，小明提交下载任务后就去干别的，听到“叮”的一声就知道完成了（异步体现在：下载完成“叮”一声通知；非阻塞体现在：等待下载完成“叮”一声通知过程中，去干别的任务了，只需要接收“叮”声通知即可；【软件处理下载任务，小明处理其他任务，不需关注进度，只需接收软件“叮”声通知，即可】

::: tip
总结：同步和异步仅仅是关注的消息如何通知的机制，如何发起调用。而阻塞与非阻塞关注的是等待消息通知时的状态，同步的情况下，是由处理消息者自己去等待消息是否被触发，而异步的情况下是由触发机制来通知处理消息者
:::

###   基础知识

#### （1）内核空间和用户空间

&emsp;&emsp;虚拟内存被操作系统划分成两块：**内核空间和用户空间**，**内核空间**是内核代码运行的地方，**用户空间**是用户程序代码运行的地方。当进程运行在内核空间时就处于内核态，当进程运行在用户空间时就处于用户态。主要目的时起到一个隔离作用，当用户的程序发生崩溃不会影响系统内核。

&emsp;&emsp;内核空间可以执行任何命令，调用一切系统资源，用户空间只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（又称 system call），才能向内核发出指令。

![image-20210705120932809](/img/note/image-20210705120932809.png)

#### **（2）进程切换：**

为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化：

1. 保存处理器上下文，包括程序计数器和其他寄存器。

2. 更新PCB信息,

   > 他是存放进程的管理和控制信息的数据结构，用来描述和控制进程的运行，总称：（PCB Process Control Block）。它是进程实体的一部分，是操作系统中最重要的记录性数据结构。
   >
   > 每一个进程均有一个PCB，在创建进程时，建立PCB，伴随进程运行的全过程，直到进程撤消而撤消

3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。

4. 选择另一个进程执行，并更新其PCB。

5. 更新内存管理的数据结构。

6. 恢复处理机上下文。

#### **（3）进程的阻塞：**

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的

#### **（4）文件描述符：**

linux系统中把一切都看成是文件，当进程打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符（File descriptor），文件描述符就是内核为了高效管理已被打开的文件所创建的索引，用来指向被打开的文件，所有执行I/O操作的系统调用都会通过文件描述符。文件描述符在形式上是一个非负整数。

-  每一个文件描述符会与一个打开文件相对应，相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。
- 不同的文件描述符也有可能指向同一个文件，相同的文件可以被不同的进程打开也可以在同一个进程中被多次打开。
- 内核对所有打开的文件的文件维护有一个系统级的描述符表格（open file description table）。有时，也称之为打开文件表（open file table），并将表格中各条目称为打开文件句柄（open file handle）。
-  系统为维护文件描述符，建立了三个表：

![preview](/img/note/wenjianmiaoshufu)

通过两个进程来演示进程文件描述符表、打开文件表（系统文件描述符表）以及i-node三个表之间的关系：

![image-20210705125555870](/img/note/image-20210705125555870.png)

​	在进程A中，文件描述符1和30都指向了同一个打开的文件句柄（标号23）。这可能是通过调用dup()、dup2()、fcntl()或者对同一个文件多次调用了open()函数而形成的。
​    进程A的文件描述符2和进程B的文件描述符2都指向了同一个打开的文件句柄（标号73）。这种情形可能是在调用fork()后出现的（即，进程A、B是父子进程关系），或者当某进程通过UNIX域套接字将一个打开的文件描述符传递给另一个进程时，也会发生。再者是不同的进程独自去调用open函数打开了同一个文件，此时进程内部的描述符正好分配到与其他进程打开该文件的描述符一样。
​    此外，进程A的描述符0和进程B的描述符3分别指向不同的打开文件句柄，但这些句柄均指向i-node表的相同条目（1976），换言之，指向同一个文件。发生这种情况是因为每个进程各自对同一个文件发起了open()调用。同一个进程两次打开同一个文件，也会发生类似情况。

#### **（5）inode是什么**

理解inode，要从文件储存说起，文件储存在硬盘上，硬盘的最小存储单位叫做"扇区"（Sector），每个扇区储存512字节（相当于0.5KB）。操作系统在读取硬盘的时候为了提高效率不会一个扇区一个扇区的读取，而是一次性读取一个块（block），一个块由多个扇区组成，常见大小为4kb（8个扇区），块是文件存取的最小单位。

文件的数据存储在块中，而文件的元数据，比如：创建者，创建日期，文件大小等元数据信息则存储在inode中（除了文件名），中文被称为索引节点。每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。

> inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。
>
> 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。
>
> 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令：  df -i

**文件描述符也是一种资源，有大小限制；linux把一切看成文件，那么系统下一切的操作都有可能占用文件描述符，例如：普通文件的读写，web请求链接，端口监听等等，如果过多的web请求未被及时释放，有可能造成占用过多的文件描述符，而导致Too many open files错误。**



#### **（6）缓存IO** 

缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

**缓存 I/O 的缺点：** 数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

#### **（7）五种IO模式**

**为什么会产生五种IO模型？**

对于一次读read操作，数据会先被拷贝到系统内核缓冲区（内核空间），然后再从系统内核缓冲区拷贝到进程地址空间（用户空间）；所以说，当一个read操作发生时，它会经历两个阶段：

1.  等待数据准备 (Waiting for the data to be ready)，将数据读取到内核缓冲区

2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)，从系统内核空间拷贝到用户空间

   > 所以针对网络IO的读和写也都分为两步：
   >
   > 1、操作系统的一次写操作分为两步：将数据从用户空间拷贝到系统空间；从系统空间往网卡写。
   >
   > 2、一次读操作分为两步：将数据从网卡拷贝到系统空间；将数据从系统空间拷贝到用户空间。

**正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。**

1.  阻塞 I/O（blocking IO）
2.  非阻塞 I/O（nonblocking IO）
3.  I/O 多路复用（ IO multiplexing）
4.  信号驱动 I/O（ signal driven IO）
5.  异步 I/O（asynchronous IO）

简单理解五种IO模型：

- 阻塞I/O：同步阻塞
- 非阻塞I/O：同步（轮询）非阻塞
- I/O多路复用：同步阻塞（不过可以同时监听多个socket状态，效率高了）
- 信号驱动I/O：异步非阻塞
- 异步I/O：真正意义上的异步非阻塞（上面的都只是数据准备阶段，这个是数据准备和数据处理阶段）

### Unix网络编程5种I/O模型

####  (1) 阻塞式I/O模型

![img](/img/note/b7c92f50bb7d.png)

recvfrom：本函数用于从（已连接）[套接口](https://baike.baidu.com/item/套接口)上接收数据（例如访问系统内核，查看有无数据返回），并捕获数据发送源的地址,当用户进程调用了recvfrom这个系统调用，系统内核就开始了IO的工作：

1. **第一阶段准备数据：**（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候系统内核就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。**准备过程中是被阻塞的**
2. **第二阶段复制数据**：当系统内核一直等到数据准备好了，它就会将数据从系统内核中拷贝到用户内存，然后系统内核返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。**拷贝过程中是被阻塞的**

**这两个阶段在阻塞IO中都会被阻塞**

#### (2) 非阻塞式I/O模型

![img](/img/note/f6b6c78dbb6f.png)

简介：nonblocking IO非阻塞IO的特点是用户进程需要**不断的主动询问**内核数据好了没有（多次系统调用，并马上返回）；

&emsp;&emsp; **第一阶段轮询系统内核查看数据是否准备就绪**:我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是马上返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。**数据 准备过程中不是被阻塞的**

&emsp;&emsp;**第二阶段数据复制**： 将数据从内核空间拷贝到用户空间，数据拷贝过程中是被阻塞的

**这两个阶段在非阻塞IO中等待阶段没有被阻塞，数据拷贝阶段是被阻塞的；**

#### (3) I/O多路复用（事件驱动）模型

![img](/img/note/eb8fb0b375be.png)

  - I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
  - 目前支持I/O多路复用的系统函数有 select，pselect，poll，epoll，他们本质上都是阻塞IO。因为他们都需要在读写事件就绪后自己负责进行读写（数据拷贝过程），也就是说这个读写过程（数据拷贝）是阻塞的
  - 多路复用能实现同时对多个IO端口进行监听（监听多个文件描述符），然后每个IO本质上是阻塞IO，事件到达执行阻塞IO的两阶段操作。
  - 当用户进程调用了select，那么整个进程会被block，而同时，内核会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从内核l拷贝到用户进程。然后继续监视....

#### (4) 信号驱动式I/O(SIGIO)

![img](/img/note/f3d00c7719c9.png)

 简介：两次调用，两次返回；

&emsp;&emsp;首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据

#### (5) 异步I/O模型

![img](/img/note/b02e69957819.png)

 简介：数据拷贝的时候进程无需阻塞。

   当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作

&emsp;&emsp;**I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写（数据拷贝）操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行（数据拷贝），也就是说这个数据拷贝过程是阻塞的，而异步I/O则无需自己负责进行读写（数据拷贝），异步I/O的实现会负责把数据从内核拷贝到用户空间**。



#### （6） I/O模型的比较，同步IO、异步IO、阻塞IO、非阻塞IO：

![img](/img/note/f767398e6060.png)

一个IO操作可以分为两个步骤：发起IO请求和实际的IO操作。根据上述5种IO模型，前4种模型-阻塞IO、非阻塞IO、IO复用、信号驱动IO都是会阻塞的I/O模型，因为其中真正的I/O操作将阻塞进程（阻塞于recvfrom调用），在内核数据copy到用户空间时都是阻塞的。

> 1、操作系统的一次写操作分为两步：将数据从用户空间拷贝到系统空间；从系统空间往网卡写。
> 
> 2、一次读操作分为两步：将数据从网卡拷贝到系统空间；将数据从系统空间拷贝到用户空间。
> 阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。
> 同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO，因此阻塞IO、非阻塞IO、IO复用、信号驱动IO都是同步IO，如果不阻塞，而是操作系统做完IO两个阶段的操作再将结果返回，那么就是异步IO。

### IO多路复用机制

####  1 IO多路复用机制

&emsp;&emsp;IO多路复用，就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。

&emsp;&emsp;从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视socket，以及调用select函数的额外操作，效率更差。但是，使用select以后最大的优势是**用户可以在一个线程内同时处理多个socket的IO请求**。用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在同一个线程内同时处理多个IO请求的目的.(这在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。)

&emsp;&emsp;IO多路复用方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只注册自己感兴趣的socket或者IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高CPU的利用率。

&emsp;&emsp;**由于select函数是阻塞的，因此多路IO复用模型也被称为异步阻塞IO模型。注意，这里的所说的阻塞是指select函数执行时线程被阻塞，而不是指socket**。一般在使用IO多路复用模型时，socket都是设置为NONBLOCK的，不过这并不会产生影响，因为用户发起IO请求时，数据已经到达了，用户线程一定不会被阻塞。

&emsp;&emsp;IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因为它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO，而非真正的异步IO。

![img](/img/note/247bcb93f8cb.png)

#### 2  select、poll、epoll系统函数简介

&emsp;&emsp;Linux支持IO多路复用的系统调用有select、poll、epoll，这些调用都是内核级别的。但select、poll、epoll本质上都是同步I/O，先是block住等待就绪的socket，再是block住将数据从内核拷贝到用户内存。select、poll、epoll之间的区别，如下表：

![image-20210705183728005](/img/note/image-20210705183728005.png)

**(1) select**

- select函数用来监视文件描述符fd，该函数会阻塞，直到有文件描述符就绪（可读可写或超时..）才会返回；当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。
- select的单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。
- select对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。
- 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

**(2) poll**

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历

- 它没有最大连接数的限制，原因是它是基于链表来存储的
- 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义
- poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

**(3) epoll**

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。epoll和select，poll函数的区别在于，select和poll必须遍历所有文件描述符，监控每一个的状态。而epoll是通过：当一个文件描述符就绪时会调用系统的回调函数，将这个文件描述符放到一个哈希表里，这个哈希表里的文件描述符都是就绪的。后续线程直接可以从这个列表中取，这样在用户空间和内核空间的copy只需一次。

select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。详细介绍： https://segmentfault.com/a/1190000003063859

#### 3 IO 零拷贝

计算机虚拟内存存储资源的空间分为内核空间和用户空间，内核空间是内核代码运行的地方，用户空间是用户程序代码运行的地方。当进程运行在内核空间时就处于内核态，当进程运行在用户空间时就处于用户态。主要起到一个隔离作用，当用户的程序发生崩溃不会影响系统内核。通常为了系统安全考虑，用户的应用程序访问计算机硬件资源都需要操作系统内核去访问。

**（1）DMA技术 传统的数据读写：**

> DMA：Direct Memory Access，存储器直接访问”。它是指一种高速的数据传输操作，允许在外部设备和存储器之间直接读写数据，既不通过CPU而直接与系统内存交换数据的接口技术

![img](/img/note/clipboard1.png)

**由上面图知,传统io需要经过4次copy**：

1.  从硬盘 经过 DMA 拷贝 到 kernel buffer 内核空间
2.  从kernel buffer内核空间经过cpu 拷贝到 user buffer（用户空间）,比如拷贝到应用程序
3.  从user buffer（用户空间）经过cpu拷贝到 socket buffer 
4. 从socket bufferDMA 拷贝到 protocol engine 协议栈

 **3次状态切换：**

- 第一次状态切换： 用户态---》 内核状 
- 第二次状态切换： 内核状---》 用户状
- 第三次状态切换： 用户状---》 内核状

**java代码体现：**

```java
		File file = new File("index.html");
        RandomAccessFile raf = new RandomAccessFile(file, "rw");
        byte[] arr = new byte[(int) file.length()];
        raf.read(arr); // 1,2
        //read 调用导致用户态到内核态的一次变化,并执行DMA 和1,2步骤
        
        
        Socket socket = new ServerSocket(8080).accept();
        socket.getOutputStream().write(arr); //执行3,4步骤
        //write 方法返回，再次从内核态切换到用户态
```

**整个过程一共经理了4次拷贝，那么如何优化这个流程呢？**

**（2）mmap映射优化技术**

mmap 通过内存映射，将磁盘文件直接映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的CPU拷贝次数。

![img](/img/note/clipboard2.png)

1.  经过 DMA 拷贝 将数据拷贝到 kernel buffer 内核空间，因为user buffer 与kernel buffer共享数据 ，所以不需要将数据从kernel buffer 拷贝到 user buffer , 数据可以直接在内核空间修改。
2.  kernel buffer内核缓冲区 中的数据经过 cpu 拷贝到 socket buffer 
3.  socket buffer 过DMA拷贝到protocol engine 

整个过程经历3次拷贝，比之前少了一次cpu拷贝，但是状态切换仍然是3次。

**（3） sendFile函数实现了真正的零拷贝（Linux2.4) **

sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区拷贝到 协议栈

![img](/img/note/clipboard3.png)

1. 第一次拷贝： DMA拷贝，将数据从硬盘拷贝到kernel buffer 
2. 第二次拷贝： DMA拷贝，将数据从kernel buffer拷贝到protocol engine协议栈
3. 没有经过cpu拷贝，也就是操作系统级别的拷贝，实现了真正的零拷贝

**四 kafka中的零拷贝**

Kafka的消息时存储在分区上的，是基于文件存储来保证有序的。Kafka的消息会有多个订阅者，生产者发布的消息会被不同的消费者多次消费，为了优化这个流程，Kafka使用了“零拷贝技术”，“零拷贝技术”只用将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中（发送给不同的订阅者时，都可以使用同一个页面缓存），避免了重复复制操作。

如果有10个消费者，传统方式下，数据复制次数为4*10=40次，而使用“零拷贝技术”只需要1+10=11次，一次为从磁盘复制到页面缓存，10次表示10个消费者各自读取一次页面缓存

**为什么单线程的Redis这么快？**

[**https://www.jianshu.com/p/b08c1f3bb256**](https://www.jianshu.com/p/b08c1f3bb256)

参考：[Linux IO模式及 select、poll、epoll详解](https://segmentfault.com/a/1190000003063859)